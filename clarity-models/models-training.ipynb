{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup Google Colab\n",
    "\n",
    "Clone the Repository and set the working directory to the clarity-models folder."
   ],
   "id": "4e02f0af892b7eea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!git clone https://github.com/omarelbeltagy/clarity",
   "id": "7972b345d949a0ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Set the runtime type to GPU:\n",
    "1. Click on \"Runtime\" in the top menu.\n",
    "2. Select \"Change runtime type\".\n",
    "3. In the popup window, choose \"GPU\" from the \"Hardware accelerator\" dropdown menu.\n",
    "4. Click \"Save\"."
   ],
   "id": "739cfb1001b54ae6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Get Dependencies\n",
    "\n",
    "Install the required packages from the requirements file."
   ],
   "id": "18c6ff4f3eae81b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip uninstall -y torch torchvision torchaudio tensorflow jax jaxlib cupy-cuda12x cudf-cu12 dask-cudf-cu12 pylibcudf-cu12\n",
    "!pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0\n",
    "!pip install transformers[torch]==4.57.1 accelerate peft bitsandbytes\n",
    "!pip install datasets fastapi uvicorn loguru PyYAML sentencepiece tensorboard==2.19.0 pandas==2.2.2 requests==2.32.4 pillow==11.1.0 pydantic==2.11.3 protobuf==5.29.1 numpy==2.1.0"
   ],
   "id": "cedadbbf1a4912fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Set Working Directory\n",
    "\n",
    "Set the current working directory to the clarity-models folder."
   ],
   "id": "1569b63ad59afec1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%cd /content/clarity/clarity-models",
   "id": "bb8555ac8545aab9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Check Environment\n",
    "\n",
    "Print out the versions of Python, PyTorch, and check for GPU availability."
   ],
   "id": "aa9b737e58df7009"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ],
   "id": "5f9a20be275c4007",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Configure Model\n",
    "\n",
    "Set up a custom configuration for training the model."
   ],
   "id": "944f68f92ad9b6fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "encoder_config = \"\"\"\n",
    "models:\n",
    "  - name: \"roberta-large\"\n",
    "    type: \"encoder\"\n",
    "    enabled: true\n",
    "\n",
    "    model_config:\n",
    "      model_name: \"roberta-large\"\n",
    "      use_8bit: true\n",
    "      output_dir: \"/content/drive/MyDrive/clarity-models-trained/roberta-large/\"\n",
    "\n",
    "    training_config:\n",
    "      max_length: 256\n",
    "      batch_size: 2\n",
    "      gradient_accumulation_steps: 8\n",
    "      learning_rate: 3e-4\n",
    "      num_epochs: 3\n",
    "\n",
    "    label_config:\n",
    "      labels:\n",
    "        - \"Clear Reply\"\n",
    "        - \"Clear Non-Reply\"\n",
    "        - \"Ambivalent\"\n",
    "\"\"\"\n",
    "\n",
    "lora_config = \"\"\"\n",
    "models:\n",
    "  - name: \"opt-6.7b\"\n",
    "    type: \"lora\"\n",
    "    enabled: true\n",
    "\n",
    "    model_config:\n",
    "      model_name: \"facebook/opt-6.7b\"\n",
    "      use_8bit: true\n",
    "      output_dir: \"/content/drive/MyDrive/clarity-models-trained/facebook/opt-6.7b/\"\n",
    "\n",
    "    training_config:\n",
    "      max_length: 256\n",
    "      batch_size: 2\n",
    "      gradient_accumulation_steps: 8\n",
    "      learning_rate: 3e-4\n",
    "      num_epochs: 3\n",
    "\n",
    "    label_config:\n",
    "      labels:\n",
    "        - \"Clear Reply\"\n",
    "        - \"Clear Non-Reply\"\n",
    "        - \"Ambivalent\"\n",
    "\"\"\"\n",
    "\n",
    "with open('ipynb-config.yaml', 'w') as f:\n",
    "    f.write(lora_config)\n",
    "\n",
    "print(\"Configuration saved to ipynb-config.yaml\")"
   ],
   "id": "179499bd66f08e75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## List available Models\n",
    "\n",
    "Print out the available models based on the configuration file to verify setup."
   ],
   "id": "c546fe9345f09dfa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python app.py --config ipynb-config.yaml list",
   "id": "83e21e8658914174",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train the Model\n",
    "\n",
    "Start training the model using the specified configuration. The output will be saved to Google Drive."
   ],
   "id": "b640f6766fce1b44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive to save the trained model\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Train the model with the specified configuration\n",
    "!python app.py --config ipynb-config.yaml train --tensorboard"
   ],
   "id": "f0059ee5bb36c99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test the Model\n",
    "\n",
    "Test the trained model with a sample question and answer."
   ],
   "id": "cefafedc44d67393"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Single prediction\n",
    "!python app.py --config ipynb-config.yaml test --question \"Will you invite them to the White House?\" --answer \"We are ready if they are serious.\""
   ],
   "id": "21a7c42241faa4d2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
