{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup Google Colab\n",
    "\n",
    "Clone the Repository and set the working directory to the clarity-models folder."
   ],
   "id": "4e02f0af892b7eea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!git clone https://github.com/yourusername/clarity-models.git\n",
    "%cd clarity-models"
   ],
   "id": "7972b345d949a0ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Get Dependencies\n",
    "\n",
    "Install the required packages from requirements.txt."
   ],
   "id": "18c6ff4f3eae81b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T12:21:08.688732Z",
     "start_time": "2025-10-29T12:21:08.540309Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -r requirements.txt",
   "id": "cedadbbf1a4912fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/bin/bash: line 1: pip: command not found\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Check Environment\n",
    "\n",
    "Print out the versions of Python, PyTorch, and check for GPU availability."
   ],
   "id": "aa9b737e58df7009"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:40:52.923385Z",
     "start_time": "2025-10-29T11:40:52.786698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ],
   "id": "5f9a20be275c4007",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU Available: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Configure Model\n",
    "\n",
    "Set up a custom configuration for training a LoRA model based on Facebook's OPT-6.7B"
   ],
   "id": "944f68f92ad9b6fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config = \"\"\"\n",
    "models:\n",
    "  - name: \"opt-6.7b\"\n",
    "    type: \"lora\"\n",
    "    enabled: true\n",
    "\n",
    "    model_config:\n",
    "      model_name: \"facebook/opt-6.7b\"\n",
    "      use_8bit: true\n",
    "\n",
    "    training_config:\n",
    "      max_length: 256\n",
    "      batch_size: 2\n",
    "      gradient_accumulation_steps: 8\n",
    "      learning_rate: 3e-4\n",
    "      num_epochs: 3\n",
    "\n",
    "    label_config:\n",
    "      labels:\n",
    "        - \"Clear Reply\"\n",
    "        - \"Clear Non-Reply\"\n",
    "        - \"Ambivalent\"\n",
    "\"\"\"\n",
    "\n",
    "# Write config (choose one)\n",
    "with open('ipynb-config.yaml', 'w') as f:\n",
    "    f.write(config)\n",
    "\n",
    "print(\"Configuration saved to ipynb-config.yaml\")"
   ],
   "id": "179499bd66f08e75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## List available Models\n",
    "\n",
    "Print out the available models based on the configuration file to verify setup."
   ],
   "id": "c546fe9345f09dfa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!python app.py --config ipynb-config.yaml list",
   "id": "83e21e8658914174"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train the Model\n",
    "\n",
    "Start training the model using the specified configuration."
   ],
   "id": "b640f6766fce1b44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!python app.py --config ipynb-config.yaml --tensorboard train",
   "id": "77bd46ad587193dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## View Training Progress\n",
    "\n",
    "Launch TensorBoard to monitor training progress. Do this while training is running in another cell."
   ],
   "id": "daf5d76a6d01d5ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./.artifacts/"
   ],
   "id": "854653e24378fb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test the Model\n",
    "\n",
    "Test the trained model with a sample question and answer."
   ],
   "id": "cefafedc44d67393"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Single prediction\n",
    "!python app.py test --question \"Will you invite them to the White House?\" --answer \"We are ready if they are serious.\""
   ],
   "id": "21a7c42241faa4d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save Model to Drive\n",
    "\n",
    "Save the trained model to Google Drive for later use."
   ],
   "id": "4bb8e88f238ea7e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy trained model to Drive\n",
    "!cp -r ./.artifacts /content/drive/MyDrive/clarity-models-trained/\n",
    "\n",
    "print(\"Model saved to Google Drive!\")"
   ],
   "id": "d91c09f9e36add3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Download Model\n",
    "\n",
    "Download the trained model as a zip file to your local machine."
   ],
   "id": "c6baf42424c8af85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create zip of trained model\n",
    "!zip -r trained_model.zip ./.artifacts/\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "\n",
    "files.download('trained_model.zip')"
   ],
   "id": "dc10251dc265173a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
